<h1>Caracter√≠sticas de RDS</h1>
RDS (Relational Database Service) es un servicio de AWS enfocado a bases de datos relacionales con compatibilidad a 6 motores de bases de datos: Amazon Aurora, MySQL, MariaDB, PostgreSQL, Oracle y Microsoft SQL Server, cada uno con sus caracter√≠sticas, integraciones y limitaciones.

Entre sus caracter√≠sticas principales podemos destacar los backups autom√°ticos con un tiempo de retenci√≥n de hasta 35 d√≠as, es decir, si encontramos alg√∫n problema con nuestras bases de datos podemos restablecerlas a la hora, minuto y segundo que necesitemos dentro del periodo de retenci√≥n. Recuerda que por defecto este periodo es de 7 d√≠as. Tambi√©n tenemos la opci√≥n de hacer backups manuales, podemos tomar snapshots manuales en cualquier momento si nuestra aplicaci√≥n lo necesita. Adem√°s, AWS por defecto tomar√° un snapshot final de nuestras bases de datos antes de eliminarlas, as√≠ podremos restablecerla si tenemos alg√∫n inconveniente.

Todas las bases de datos relacionales utilizan un sistema de almacenamiento, si la carga de lectura y escritura son constantes, el sistema General Purpose funciona muy bien, sin embargo, podemos utilizar el sistema Provisioned Storage cuando requerimos de altas cantidades de consumo y operaciones de disco.

RDS es un sistema completamente administrado, esto quiere decir que AWS reduce nuestra carga operativa automatizando muchas tareas de nuestra base de datos, por ejemplo, las actualizaciones. A nivel de seguridad contamos con muchas opciones, una de ellas es la posibilidad de encriptar nuestra base de datos para que solo nosotros y las personas o roles que especifiquemos tengan acceso.

Tambi√©n tenemos integraci√≥n con otros servicios de AWS, por ejemplo, IAM para administrar a los usuarios, roles, grupos y pol√≠ticas de conexi√≥n a la base de datos por medio de tokens con m√°ximo 20 conexiones por segundo (recomendado para escenarios de prueba), o la integraci√≥n de Enhanced monitoring para hacer monitoreo en tiempo real nuestras bases de datos (recuerda que adem√°s de subir el precio, no est√° disponible para instancias small).


Por defecto hace backups diariamente y lo retiene 7 dias. Puedes ampliar a 35 d√≠as de retenci√≥n. Tambi√©n es posible ahcer un snapshot manual de la base de datos.

Integracion con IAM mediante tokens de 10 a 20 conexiones por segundo.

Motores de DB admitidos -> Amazon Aurora, MySQL, MariaDB, PostgreSQL, Oracle y Microsoft SQL Server

IOPS -> input/output operations per second is an input/output performance measurement used to characterize computer storage devices like hard disk drives, solid state drives, and storage area networks.


RDS CON SQL

Puerto por defecto SQL 3306

Cuando utilizamos el servicio RDS con el motor de MySQL podemos crear multiples bases de datos con un solo endpoint (una sola conexi√≥n), ya que entre las caracter√≠sticas de este motor encontramos la cantidad de bases de datos ilimitada. Obviamente, debemos tener en cuenta que nuestras instancias deber√≠an soportar la cantidad de bases de datos que vamos a utilizar, y las herramientas de monitoreo nos pueden ayudar a medir esta relaci√≥n de tama√±o y rendimiento.

Recuerda que si necesitamos un permiso de usuarios diferente para cada base de datos vamos a necesitar configuraciones diferentes en las keys (llaves de acceso) de nuestra instancia.

A nivel de monitoreo, AWS nos provee un servicio llamado CloudWatch que nos permite visualizar los niveles de lectura, escritura, CPU, disco y memoria de la instancia d√≥nde corre nuestra base de datos, tambi√©n podemos analizar las m√©tricas de conexiones para determinar la carga y la concurrencia de nuestras instancias.

La primer estrategia para mejorar el performance son las replicas de lectura, copias as√≠ncronas de nuestra base de datos principal con un nuevo endpoint que vamos a utilizar solo en tareas de lectura, as√≠ obtenemos mucha m√°s disponibilidad para tareas de escritura en nuestra base de datos principal. Recuerda que este servicio no esta disponible para los motores de Oracle y SQL Server.

Tambi√©n podemos mejorar el storage de nuestra base de datos utilizando provisioned iops para soportar altas operaciones de entrada y salida sobre la base de datos, principalmente para transacciones OLTP (OnLine Transaction Processing).

Existen otras alternativas como las bases de datos en memoria (ElastiCache, por ejemplo). Estas opciones resultan muy √∫tiles para guardar la informaci√≥n m√°s consultada en cache, as√≠ aliviamos un poco la carga de nuestra base de datos principal. Si estamos muy saturados y agotamos todas las opciones para mejorar el performance, la recomendaci√≥n es dividir nuestra base de datos en otras m√°s peque√±as.

Multi AZ nos permite tener alta disponibilidad de nuestra base de datos, creando bases de datos replica que autom√°ticamente vamos a utilizar cuando la base de datos principal tenga problemas üì°.
Recomendado para ambientes de producci√≥n üí•.
La replicaci√≥n es s√≠ncrona üéè.
Los backups se hacen en la base de datos Standby(la que no estamos utilizando) üëç.
El precio es el mismo que al tener dos bases de datos üò±.
No confundir con las replicas de lectura üòÖ.


DMS (Database Migration Service) es un servicio de AWS que nos permite migrar nuestras bases de datos con otros motores al servicio de RDS u otros servicios de bases de datos en AWS.

Este servicio tiene las siguientes caracter√≠sticas:

    - Podemos realizar migraciones de bases de datos on premise o en la nube a los servicios de bases de datos en AWS sin afectar el downtime de la base de datos que - vamos a migrar.
    - La carga de trabajo durante las migraciones es adaptable.
    - Solo pagamos por los recursos que utilizamos en la migraci√≥n.
    - AWS administra la infraestructura necesaria para el trabajo de la migraci√≥n, Hardware, Software, parches, etc.
    - Conmutaci√≥n por error autom√°tica, si AWS detecta un error en el proceso autom√°ticamente crear√° una nueva instancia para remplazar la anterior, as√≠ el proceso de - replicaci√≥n no se ve afectado por estos problemas.
    - Los datos en reposo est√°n cifrados con KMS (Key Management Service) y la migraci√≥n utiliza el protocolo de seguridad SSL.


Las migraciones homog√©neas son migraciones donde la base de datos de origen y la de destino puede tener diferentes versiones del mismo motor, o son bases de datos compatibles entre s√≠ (MySQL y Aurora, por ejemplo).

Tambi√©n podemos realizar migraciones heterog√©neas, donde la base de datos de origen no es compatible con la de destino. Estas migraciones NO siempre son posibles, y antes de realizar la migraci√≥n vamos a necesitar convertir el esquema de la base de datos con la herramienta AWS Schema Conversion Tool.   
**AURORA**


AWS recomiendo a Aurora (est√° desarollada por ellos) asegurando 5x velocidad a motores SQL y 3 x a mototres POSTGRESQL

Adem√°s de ser una base de datos muy potente y robusta, Aurora nos permite un nivel de customizaci√≥n muy alto, puede crecer hasta 64 TB y nuestra data esta replicada en m√∫ltiples Az.

    Otras caracter√≠sticas de Aurora:

        - Autoreparaci√≥n: Guardar la informaci√≥n de la parte da√±ada en otra parte del disco y reparar el problema autom√°ticamente.
        - Cache Warm: Hacer un precalentamiento de la cach√© al iniciar las consultas m√°s comunes y sus resultados.
        - Recuperaci√≥n de accidentes: Si falla la instancia principal, Aurora promueve una r√©plica de lectura o crea una nueva instancia principal.

        
**DYNAMODB**

DynamoDB es el servicio para bases de datos NOSQL de AWS completamente administrado (AWS se encarga de todo el background para que nosotros trabajemos nuestra aplicaci√≥n), compuesto de varios nodos y distribuido en varias regiones (altamente disponible con replicaci√≥n en diferentes locaciones), es una base de datos de baja latencia con almacenamiento en cach√© y es completamente escalable sin downtime de nuestra aplicaci√≥n.

Este servicio se basa en dos conceptos importantes: las unidades en lectura (RCU, 4kb de bloques por segundo) y las unidades de escritura (WRU, 1kb de bloques por segundo). Con base en estos dos par√°metros se determina el costo de nuestras bases de datos y el autoescalamiento.

La unidad fundamental de DynamoDB son las tablas, que est√°n compuestas por items, que est√°n compuestos por atributos (por ejemplo, la tabla trabajadores est√° compuesta por, trabajadores, cada uno con su nombre, edad, identificaci√≥n y toda su informaci√≥n). Tambi√©n debemos entender los conceptos de partition key (llaves primarias para el espacio de almacenamiento) , sort keys (para organizar y ordenar la informaci√≥n) y local and global secondary index (otros atributos que podemos utilizar junto a las partition keys u otros atributos para obtener informaci√≥n m√°s especifica y con mejor rendimiento).

    - **Consitencia de Lectura**

La consistencia eventual de lectura NO puede mostrar los resultados de una tarea de escritura reciente cuando consultamos una tabla reci√©n actualizada, adem√°s, consume los 4kb de bloques por segundo en las unidades de lectura.

Por otra parte, la consistencia fuerte de lectura funciona correctamente cuando consultamos una tabla y recibimos la respuesta m√°s reciente, pero consume el doble que la consistencia eventual, as√≠ que ser√° m√°s costosa. Este tipo de consistencia es el adecuando para aplicaciones y casos de uso muy espec√≠ficos donde la consulta y la escritura deben estar tan sincronizadas como sea posible.

CASOS DE USO PARA DYNAMODB

El servicio de DynamoDB es muy √∫til en los siguientes casos:

Aplicaciones m√≥viles
Internet de las cosas (IoT, gracias al real time y su capacidad para ingesta de informaci√≥n)
Aplicaciones Web
Gaming (gracias a su alta disponibilidad, conexi√≥n y por ser no relacional)
Manejo de sesiones
RealTime (ya que no solo nos permite almacenar nuestra informaci√≥n, tambi√©n podemos utilizar toda la data en tiempo real para alimentar otros servicios y generar otras arquitecturas)


PARTICIONES DYNAMO

    - En DynamoDB las tablas se almacenan en particiones üì¶
    - La base de datos asigna las particiones de cada tabla y puede aumentar su tama√±o para mejorar el desempe√±o o a√±adir m√°s particiones cuando la partici√≥n esta llena üõ≥
    - Las particiones pueden aumentar su tama√±o hasta 10GB siempre y cuando no superemos los 3.000 niveles de lectura y 1.000 de escritura üêò
    - Para almacenar elementos utilizamos claves principales simples o compuestas, DynamoDB utiliza estas claves para asignar las particiones ü§î
    - Entre m√°s aleatorias sean las claves principales, mejor performance tiene la base de datos üéâ
    - Cuando utilizamos claves compuestas, el orden de los elementos depende de la clave de ordenaci√≥n üí°


**scan**

Las Operaciones Scan se encargan de escanear por completo nuestras tablas para examinar todos sus elementos y comprobar si presentan los valores solicitados, pero son muy poco eficientes ya que utilizan bastantes unidades de lectura y aumentan los costos de nuestra base de datos, debemos evitar estas operaciones para tablas grandes.

AWS nos recomienda realizar operaciones peque√±as a lo largo del tiempo en vez de hacer una sola operaci√≥n muy larga, tambi√©n podemos configurar l√≠mites de tama√±o para evitar los escaneos completos y duplicar nuestras tablas para realizar estas operaciones sobre tablas no principales y no afectar su rendimiento.

    - Las operaciones scan examinan los elementos de nuestras tablas para comprobar sus valores ü§ì
    - Son completamente ineficientes y deber√≠amos evitarlas üëé üò•üò†
    - Pueden gastar todos los niveles de lectura de la base de datos
    - Haciendo operaciones peque√±as a lo largo del tiempo y configurando l√≠mites podemos evitar el escaneo completo y subir los precios ü§î
    - Si duplicamos las tablas para las operaciones NO afectamos el performance de las tablas principales üÜó

**QUERY**

Las Operaciones Query (operaciones de consulta) nos permiten buscar elementos en cualquier tabla o √≠ndice secundario en base a su clave principal compuesta para optimizar la petici√≥n.

En vez de escanear toda la tabla (como en las operaciones Scan), vamos a especificar los criterios de b√∫squeda utilizando una expresi√≥n de condici√≥n clave (una cadena que determina los elementos que vamos a leer en la tabla o el √≠ndice), especificamos el nombre y valor la clave de partici√≥n como una condici√≥n de igualdad, podemos realizar consultas utilizando diferentes operadores para encontrar los resultados con mejor precisi√≥n.

Tambi√©n podemos limitar el n√∫mero de elementos que esperamos en los resultados para agilizar las operaciones, pero no obtenemos informaci√≥n tan detallada de la capacidad de lectura que consumimos.

El desaf√≠o de esta clase es responder en la secci√≥n de comentarios un caso de uso de DynamoDB y cu√°les serian sus ventajas frente a los servicios RDS.

**STREAMS Y REPLICACI√ìN**

DynamoDB Streams nos proporciona una secuencia ordenada por tiempo de cambios de los elementos de cualquier tabla, es decir, guarda los cambios de nuestros elementos para que podamos procesar y consumir esta informaci√≥n, podemos ampliar el poder de DynamoDB con replicaci√≥n entre regiones, an√°lisis continuo con integraci√≥n a Redshift, notificaci√≥n de cambios y muchos otros escenarios.

Estos streams capturan una secuencia en orden cronol√≥gico de las modificaciones de los elementos de una tabla y almacenan la informaci√≥n por 24 horas. Cada registro de secuencia contiene la informaci√≥n sobre una sola modificaci√≥n a los datos de un elemento de la tabla. Nuestras aplicaciones pueden obtener acceso a este registro y ver los elements de datos tal y como se encontraban antes y despu√©s.

**DAX o DINAMODB ACCELERATOR**

DAX (DynamoDB Accelerator) es un cluster de cach√© completamente administrado por AWS y de alta disponibilidad para DynamoDB con un rendimiento de hasta 10 veces superior (de milisegundos a microsegundos) y soporta millones de solicitudes por segundo.

Entre sus caracter√≠sticas encontramos la encriptaci√≥n en reposo, podemos utilizar hasta 10 nodos y se puede seleccionar la zona de disponibilidad donde se desplegar√° el cluster. Podemos utilizar instancias small y medium para cargas de prueba, de resto todas son de tipo R (optimizadas en memoria).


**CONCLUSIONES:**

- Conclusiones del servicio RDS:

Siempre que desplegamos bases de datos en producci√≥n es muy recomendado utilizar los despliegues en diferentes zonas con el servicio Multi AZ.
Tenemos diferentes estrategias para optimizar el performance de nuestra base de datos, por ejemplo, implementar r√©plicas de lectura, utilizar bases de datos en memoria y dividir la base de datos en otras m√°s peque√±as.
El periodo de retenci√≥n de los backups de nuestra base de datos son m√°ximo 35 d√≠as.
Debemos tener en cuenta los tipos de migraci√≥n (homog√©neas y heterog√©neas) cuando vamos a migrar nuestra base de datos.
AhororaDB es la base de datos m√°s robusta y potente para grandes cargas de trabajo de AWS, tambi√©n es la √∫nica con servicio de serverless y autoescalamiento.

- Conclusiones del servicio DynamoDB:

Es recomendado evitar las operaciones Scan para no afectar la capacidad aprovisionada, en cambio, las operaciones Query funcionan mucho mejor para el rendimiento de la base de datos.
La funci√≥n de autoscaling se puede programar con lectura y escritura pero debemos tener en cuenta los costos.
Es clave elegir una llave principal adecuada para no afectar el performance de nuestra base de datos, entre m√°s aleatoria sea este valor, mejor ser√° el rendimiento.
Con DynamoDB Streams podemos crear arquitecturas en tiempo real para diferentes aplicaciones.
Cuando tenemos una tabla muy grande, configurar el particionamiento y los l√≠mites del mismo son fundamentales.
